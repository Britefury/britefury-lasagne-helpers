{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digit classifier example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn of cuDNN as its convolution operations are *not reproducible*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'dnn.enabled=False, optimizer_including='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is enabled with initial size: 25.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn.cross_validation\n",
    "\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "from britefury_lasagne import basic_dnn, trainer, image_window_extractor\n",
    "\n",
    "from fuel.datasets.mnist import MNIST\n",
    "import fuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network architecture\n",
    "\n",
    "We define the `build_network` function that takes the input variables as an optional argument and build the network using the Lasagne API.\n",
    "\n",
    "NOTE that the final dense layer does *NOT* use the `softmax` nonlinearity as it is supplied by the classifier builder (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(input_vars=None):\n",
    "    # Input layer\n",
    "    x_var = input_vars[0] if input_vars is not None else None\n",
    "    net = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=x_var)\n",
    "\n",
    "    # Two 32 unit 3x3 conv layers, followed by 2x2 max-pool\n",
    "    net = lasagne.layers.Conv2DLayer(net, num_filters=32, filter_size=(5, 5), W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.MaxPool2DLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    # Two 32 unit 3x3 conv layers, followed by 2x2 max-pool\n",
    "    net = lasagne.layers.Conv2DLayer(net, num_filters=32, filter_size=(3, 3), W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.Conv2DLayer(net, num_filters=32, filter_size=(3, 3), W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.MaxPool2DLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of 64 units followed by 50% dropout\n",
    "    net = lasagne.layers.DenseLayer(net, num_units=64, W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.DropoutLayer(net, p=0.5)\n",
    "\n",
    "    # Final 10-unit dense layer, with no nonlinearity\n",
    "    net = lasagne.layers.DenseLayer(net, num_units=10, nonlinearity=None)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for resetting the random number generator seeds of the noise layers (e.g. dropout):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_noise_seeds(final_layer, rng):\n",
    "    for l in lasagne.layers.get_all_layers(final_layer):\n",
    "        if isinstance(l, (lasagne.layers.DropoutLayer, lasagne.layers.GaussianNoiseLayer)):\n",
    "            l._srng.set_rstate(rng.randint(1, 2147462579))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MNIST(which_sets=['train'], load_in_memory=True, subset=slice(0, 50000))\n",
    "mnist_val = MNIST(which_sets=['train'], load_in_memory=True, subset=slice(50000, None))\n",
    "mnist_test = MNIST(which_sets=['test'], load_in_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmp6fcseg/81125e2c9964bf5b883ec60c08118404.lib and object D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmp6fcseg/81125e2c9964bf5b883ec60c08118404.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmplhg_jc/378931d0d188abc1eb9a51d3938507cc.lib and object D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmplhg_jc/378931d0d188abc1eb9a51d3938507cc.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpf0kaco/b6437dbe3a70d5ad2b089b5e10d3d274.lib and object D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpf0kaco/b6437dbe3a70d5ad2b089b5e10d3d274.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpzwxpam/48b9799aed07df53f14a2fa9ae829dac.lib and object D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpzwxpam/48b9799aed07df53f14a2fa9ae829dac.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmp_0iurm/02ae083f274bd9021b2d6b9c859640e3.lib and object D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmp_0iurm/02ae083f274bd9021b2d6b9c859640e3.exp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1/3 took 9.65s:  TRAIN y loss=2.257261  VAL y loss=2.145790 err=64.02%  TEST y loss=2.151802 err=65.19%\n",
      "Epoch 2/3 took 9.87s:  TRAIN y loss=2.074777  VAL y loss=1.878938 err=40.17%  TEST y loss=1.885863 err=40.87%\n",
      "Epoch 3/3 took 9.74s:  TRAIN y loss=1.766350  VAL y loss=1.388147 err=22.81%  TEST y loss=1.395608 err=23.42%\n",
      "Final result:\n",
      "Epoch 3/3 took 29.26s:  TRAIN y loss=1.766350  VAL y loss=1.388147 err=22.81%  TEST y loss=1.395608 err=23.42%\n"
     ]
    }
   ],
   "source": [
    "# Create SEPARATE random number generators for generating weights, noise seeds and shuffling,\n",
    "# with specific seeds so that we can re-try the experiment below to check that we get the same result\n",
    "# Creating a network's layers draws from an RNG in order to create randomly initialised network weights.\n",
    "# Since the third experiment does not create new layers, we need separate RNGs for the noise and shuffling\n",
    "# steps so that we can ensure that they operate the same way each time\n",
    "weight_rng1 = np.random.RandomState(12345)\n",
    "noise_rng1 = np.random.RandomState(67890)\n",
    "shuffle_rng1 = np.random.RandomState(24680)\n",
    "\n",
    "# Set Lasagne's RNG\n",
    "lasagne.random.set_rng(weight_rng1)\n",
    "\n",
    "# Build the image classifier for the given model builder\n",
    "print 'Building network'\n",
    "clf = basic_dnn.simple_classifier(build_network, n_input_spatial_dims=2, target_channel_index=0,\n",
    "            updates_fn=lambda loss, params: lasagne.updates.sgd(loss, params, learning_rate=0.001))\n",
    "\n",
    "reset_noise_seeds(clf.final_layers, noise_rng1)\n",
    "\n",
    "# Get the randomly initialised parameter values so that we can try to re-start training without building\n",
    "# the net from scratch\n",
    "blank_state = clf.get_param_values(include_updates=True)\n",
    "\n",
    "# Set verbosity\n",
    "clf.trainer.report(verbosity=trainer.VERBOSITY_EPOCH)\n",
    "\n",
    "# Set training length\n",
    "clf.trainer.train_for(num_epochs=3)\n",
    "\n",
    "# Train\n",
    "print 'Training'\n",
    "clf.trainer.train(mnist_train, mnist_val, mnist_test, batchsize=128, shuffle_rng=shuffle_rng1)\n",
    "\n",
    "clf_state = clf.get_param_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network\n",
      "Training\n",
      "Epoch 1/3 took 10.04s:  TRAIN y loss=2.257261  VAL y loss=2.145790 err=64.02%  TEST y loss=2.151802 err=65.19%\n",
      "Epoch 2/3 took 10.26s:  TRAIN y loss=2.074777  VAL y loss=1.878938 err=40.17%  TEST y loss=1.885863 err=40.87%\n",
      "Epoch 3/3 took 9.91s:  TRAIN y loss=1.766350  VAL y loss=1.388147 err=22.81%  TEST y loss=1.395608 err=23.42%\n",
      "Final result:\n",
      "Epoch 3/3 took 30.21s:  TRAIN y loss=1.766350  VAL y loss=1.388147 err=22.81%  TEST y loss=1.395608 err=23.42%\n"
     ]
    }
   ],
   "source": [
    "weight_rng2 = np.random.RandomState(12345)\n",
    "noise_rng2 = np.random.RandomState(67890)\n",
    "shuffle_rng2 = np.random.RandomState(24680)\n",
    "\n",
    "lasagne.random.set_rng(weight_rng2)\n",
    "\n",
    "# Build the image classifier for the given model builder\n",
    "print 'Building network'\n",
    "clf2 = basic_dnn.simple_classifier(build_network, n_input_spatial_dims=2, target_channel_index=0,\n",
    "            updates_fn=lambda loss, params: lasagne.updates.sgd(loss, params, learning_rate=0.001))\n",
    "\n",
    "reset_noise_seeds(clf2.final_layers, noise_rng2)\n",
    "\n",
    "# Get the randomly initialised parameter values so that we can try to re-start training without building\n",
    "# the net from scratch\n",
    "blank_state2 = clf2.get_param_values(include_updates=True)\n",
    "\n",
    "# Set verbosity\n",
    "clf2.trainer.report(verbosity=trainer.VERBOSITY_EPOCH)\n",
    "\n",
    "# Set training length\n",
    "clf2.trainer.train_for(num_epochs=3)\n",
    "\n",
    "# Train\n",
    "print 'Training'\n",
    "clf2.trainer.train(mnist_train, mnist_val, mnist_test, batchsize=128, shuffle_rng=shuffle_rng2)\n",
    "\n",
    "clf2_state = clf2.get_param_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the state of the first classifier and train again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1/3 took 9.77s:  TRAIN y loss=2.255214  VAL y loss=2.146062 err=62.93%  TEST y loss=2.152184 err=64.46%\n",
      "Epoch 2/3 took 9.75s:  TRAIN y loss=2.079298  VAL y loss=1.881940 err=39.97%  TEST y loss=1.889157 err=40.48%\n",
      "Epoch 3/3 took 9.80s:  TRAIN y loss=1.773211  VAL y loss=1.399116 err=22.60%  TEST y loss=1.407584 err=23.61%\n",
      "Final result:\n",
      "Epoch 3/3 took 29.32s:  TRAIN y loss=1.773211  VAL y loss=1.399116 err=22.60%  TEST y loss=1.407584 err=23.61%\n"
     ]
    }
   ],
   "source": [
    "weight_rng3 = np.random.RandomState(12345)\n",
    "noise_rng3 = np.random.RandomState(67890)\n",
    "shuffle_rng3 = np.random.RandomState(24680)\n",
    "\n",
    "# Reset parameter state\n",
    "clf.set_param_values(blank_state, include_updates=True)\n",
    "\n",
    "# Reset noise seeds\n",
    "reset_noise_seeds(clf.final_layers, noise_rng3)\n",
    "\n",
    "# Train\n",
    "print 'Training'\n",
    "clf.trainer.train(mnist_train, mnist_val, mnist_test, batchsize=128, shuffle_rng=shuffle_rng3)\n",
    "\n",
    "clf_state_b = clf.get_param_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check parameters for equality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_states(s1, s2):\n",
    "    for i, (a, b) in enumerate(zip(s1, s2)):\n",
    "        if (a != b).any():\n",
    "            print 'FAIL at index {}/{}'.format(i, len(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_states(blank_state, blank_state2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_states(clf_state, clf2_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_states(clf_state, clf2_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL at index 0/10\n",
      "FAIL at index 1/10\n",
      "FAIL at index 2/10\n",
      "FAIL at index 3/10\n",
      "FAIL at index 4/10\n",
      "FAIL at index 5/10\n",
      "FAIL at index 6/10\n",
      "FAIL at index 7/10\n",
      "FAIL at index 8/10\n",
      "FAIL at index 9/10\n"
     ]
    }
   ],
   "source": [
    "compare_states(clf_state, clf_state_b)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}