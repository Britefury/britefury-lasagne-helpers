{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digit classifier example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn.cross_validation\n",
    "\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "from britefury_lasagne import basic_dnn, trainer, image_window_extractor, mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network architecture\n",
    "\n",
    "We define the `build_network` function that takes the input variables as an optional argument and build the network using the Lasagne API.\n",
    "\n",
    "NOTE that the final dense layer does *NOT* use the `softmax` nonlinearity as it is supplied by the classifier builder (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(input_vars=None):\n",
    "    # Input layer\n",
    "    x_var = input_vars[0] if input_vars is not None else None\n",
    "    net = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=x_var)\n",
    "\n",
    "    # A 32 unit 5x5 conv layer, followed by 2x2 max-pool\n",
    "    net = lasagne.layers.Conv2DLayer(net, num_filters=32, filter_size=(5, 5), W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.MaxPool2DLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    # Two 32 unit 3x3 conv layers, followed by 2x2 max-pool\n",
    "    net = lasagne.layers.Conv2DLayer(net, num_filters=32, filter_size=(3, 3), W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.Conv2DLayer(net, num_filters=32, filter_size=(3, 3), W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.MaxPool2DLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of 64 units followed by 50% dropout\n",
    "    net = lasagne.layers.DenseLayer(net, num_units=64, W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.DropoutLayer(net, p=0.5)\n",
    "\n",
    "    # Final 10-unit dense layer, with no nonlinearity\n",
    "    net = lasagne.layers.DenseLayer(net, num_units=10, nonlinearity=None)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = mnist.MNIST()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the image classifier for the given model builder\n",
    "print('Building network')\n",
    "clf = basic_dnn.simple_classifier(build_network, n_input_spatial_dims=2,\n",
    "            updates_fn=lambda loss, params: lasagne.updates.adam(loss, params, learning_rate=0.001))\n",
    "\n",
    "# Train with a batch size of 128, for 10 epochs, reporting after each epoch.\n",
    "print('Training')\n",
    "clf.train([dataset.train_X[:512], dataset.train_y[:512]],\n",
    "          [dataset.val_X[:512], dataset.val_y[:512]],\n",
    "          [dataset.test_X[:512], dataset.test_y[:512]], batchsize=128,\n",
    "          num_epochs=10, verbosity=trainer.VERBOSITY_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the classifier to predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict probabilities for test samples\n",
    "test_y_pred_prob = clf.predict([dataset.test_X])[0]\n",
    "# Use `np.argmax` to get class predictions\n",
    "test_y_pred = np.argmax(test_y_pred_prob, axis=1)\n",
    "\n",
    "# Show the error rate\n",
    "print('Test error rate={:.2%}'.format(np.mean(test_y_pred != dataset.test_y)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
