{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digit classifier example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVIL HACK: Disable cuDNN check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\r\n",
      "   Creating library D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpmfrmcz/265abc51f7c376c224983485238ff1a5.lib and object D:/temp/theano/compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_58_Stepping_9_GenuineIntel-2.7.11-64/tmpmfrmcz/265abc51f7c376c224983485238ff1a5.exp\r\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is enabled with initial size: 25.0% of memory, cuDNN 5103)\n",
      "d:\\packages\\theano\\theano\\sandbox\\cuda\\__init__.py:603: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn.cross_validation\n",
    "\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "from britefury_lasagne import basic_dnn, trainer, image_window_extractor\n",
    "\n",
    "from fuel.datasets.mnist import MNIST\n",
    "import fuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network architecture\n",
    "\n",
    "We define the `build_network` function that takes the input variables as an optional argument and build the network using the Lasagne API.\n",
    "\n",
    "NOTE that the final dense layer does *NOT* use the `softmax` nonlinearity as it is supplied by the classifier builder (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(input_vars=None):\n",
    "    # Input layer\n",
    "    x_var = input_vars[0] if input_vars is not None else None\n",
    "    net = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=x_var)\n",
    "\n",
    "    # A 32 unit 5x5 conv layer, followed by 2x2 max-pool\n",
    "    net = lasagne.layers.Conv2DLayer(net, num_filters=32, filter_size=(5, 5), W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.MaxPool2DLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    # Two 32 unit 3x3 conv layers, followed by 2x2 max-pool\n",
    "    net = lasagne.layers.Conv2DLayer(net, num_filters=32, filter_size=(3, 3), W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.Conv2DLayer(net, num_filters=32, filter_size=(3, 3), W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.MaxPool2DLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of 64 units followed by 50% dropout\n",
    "    net = lasagne.layers.DenseLayer(net, num_units=64, W=lasagne.init.HeUniform())\n",
    "    net = lasagne.layers.DropoutLayer(net, p=0.5)\n",
    "\n",
    "    # Final 10-unit dense layer, with no nonlinearity\n",
    "    net = lasagne.layers.DenseLayer(net, num_units=10, nonlinearity=None)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_train = MNIST(which_sets=['train'], load_in_memory=True, subset=slice(0, 50000))\n",
    "mnist_val = MNIST(which_sets=['train'], load_in_memory=True, subset=slice(50000, None))\n",
    "mnist_test = MNIST(which_sets=['test'], load_in_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network\n",
      "Training\n",
      "Epoch 1/10 took 2.28s:  TRAIN y loss=0.415059  VAL y loss=0.076682 err=2.28%  TEST y loss=0.073987 err=2.44%\n",
      "Epoch 2/10 took 2.16s:  TRAIN y loss=0.139488  VAL y loss=0.051394 err=1.58%  TEST y loss=0.041515 err=1.41%\n",
      "Epoch 3/10 took 2.11s:  TRAIN y loss=0.100317  VAL y loss=0.050638 err=1.43%  TEST y loss=0.041951 err=1.42%\n",
      "Epoch 4/10 took 2.12s:  TRAIN y loss=0.083377  VAL y loss=0.040146 err=1.18%  TEST y loss=0.029760 err=1.06%\n",
      "Epoch 5/10 took 2.45s:  TRAIN y loss=0.067431  VAL y loss=0.039101 err=0.99%  TEST y loss=0.025695 err=0.85%\n",
      "Epoch 6/10 took 2.10s:  TRAIN y loss=0.061705  VAL y loss=0.035104 err=0.94%  TEST y loss=0.023150 err=0.84%\n",
      "Epoch 7/10 took 1.95s:  TRAIN y loss=0.051253  VAL y loss=0.039927 err=0.96%\n",
      "Epoch 8/10 took 1.94s:  TRAIN y loss=0.046544  VAL y loss=0.038004 err=0.95%\n",
      "Epoch 9/10 took 2.11s:  TRAIN y loss=0.042516  VAL y loss=0.032190 err=0.83%  TEST y loss=0.019220 err=0.68%\n",
      "Epoch 10/10 took 1.95s:  TRAIN y loss=0.039956  VAL y loss=0.033426 err=0.90%\n",
      "Final result:\n",
      "Epoch 9/10 took 21.19s:  TRAIN y loss=0.042516  VAL y loss=0.032190 err=0.83%  TEST y loss=0.019220 err=0.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<britefury_lasagne.trainer.TrainingResults at 0x65750f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the image classifier for the given model builder\n",
    "print 'Building network'\n",
    "clf = basic_dnn.simple_classifier(build_network, n_input_spatial_dims=2, target_channel_index=0,\n",
    "            updates_fn=lambda loss, params: lasagne.updates.adam(loss, params, learning_rate=0.001))\n",
    "\n",
    "# Set verbosity\n",
    "clf.trainer.report(verbosity=trainer.VERBOSITY_EPOCH)\n",
    "\n",
    "# Set training length\n",
    "clf.trainer.train_for(num_epochs=10)\n",
    "\n",
    "# Train\n",
    "print 'Training'\n",
    "clf.trainer.train(mnist_train, mnist_val, mnist_test, batchsize=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the classifier to predict on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate=0.68%\n"
     ]
    }
   ],
   "source": [
    "# Get a Fuel dataset for MNIST test set, features only (no targets)\n",
    "mnist_test_features = MNIST(which_sets=['test'], sources=['features'], load_in_memory=True)\n",
    "\n",
    "# Predict probabilities for test samples\n",
    "test_y_pred_prob = clf.predict(mnist_test_features)[0]\n",
    "# Use `np.argmax` to get class predictions\n",
    "test_y_pred = np.argmax(test_y_pred_prob, axis=1)\n",
    "\n",
    "# Get the ground truths\n",
    "state = mnist_test.open()\n",
    "test_y = mnist_test.get_data(state, request=slice(None))[1]\n",
    "\n",
    "# Show the error rate\n",
    "print 'Test error rate={:.2%}'.format(np.mean(test_y_pred != test_y[:,0]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
