{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 pre-trained network example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn.cross_validation\n",
    "\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "from britefury_lasagne import basic_dnn\n",
    "from britefury_lasagne.pretrained import imagenet_vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an example image to classify\n",
    "\n",
    "Load an image containing a peacock, and extract an 896x896 (4 x 224, where 224 is the image size expected by the network) block containing the peacock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join('images', 'P1013781.JPG')\n",
    "# Extract a 896 x 896 block surrounding the peacock\n",
    "img = plt.imread(IMAGE_PATH)[1800:2696,652:1548]\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the VGG-16 network\n",
    "\n",
    "Invoke `VGG16Model.load()` to - if necessary - download the network weights, load them and construct the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg16 = imagenet_vgg.VGG16Model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the layer names, types and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input                  type InputLayer           : output_shape=(None, 3, 224, 224)\n",
      "conv1_1                type Conv2DLayer          : output_shape=(None, 64, 224, 224)\n",
      "conv1_2                type Conv2DLayer          : output_shape=(None, 64, 224, 224)\n",
      "pool1                  type Pool2DLayer          : output_shape=(None, 64, 112, 112)\n",
      "conv2_1                type Conv2DLayer          : output_shape=(None, 128, 112, 112)\n",
      "conv2_2                type Conv2DLayer          : output_shape=(None, 128, 112, 112)\n",
      "pool2                  type Pool2DLayer          : output_shape=(None, 128, 56, 56)\n",
      "conv3_1                type Conv2DLayer          : output_shape=(None, 256, 56, 56)\n",
      "conv3_2                type Conv2DLayer          : output_shape=(None, 256, 56, 56)\n",
      "conv3_3                type Conv2DLayer          : output_shape=(None, 256, 56, 56)\n",
      "pool3                  type Pool2DLayer          : output_shape=(None, 256, 28, 28)\n",
      "conv4_1                type Conv2DLayer          : output_shape=(None, 512, 28, 28)\n",
      "conv4_2                type Conv2DLayer          : output_shape=(None, 512, 28, 28)\n",
      "conv4_3                type Conv2DLayer          : output_shape=(None, 512, 28, 28)\n",
      "pool4                  type Pool2DLayer          : output_shape=(None, 512, 14, 14)\n",
      "conv5_1                type Conv2DLayer          : output_shape=(None, 512, 14, 14)\n",
      "conv5_2                type Conv2DLayer          : output_shape=(None, 512, 14, 14)\n",
      "conv5_3                type Conv2DLayer          : output_shape=(None, 512, 14, 14)\n",
      "pool5                  type Pool2DLayer          : output_shape=(None, 512, 7, 7)\n",
      "fc6                    type DenseLayer           : output_shape=(None, 4096)\n",
      "fc6_dropout            type DropoutLayer         : output_shape=(None, 4096)\n",
      "fc7                    type DenseLayer           : output_shape=(None, 4096)\n",
      "fc7_dropout            type DropoutLayer         : output_shape=(None, 4096)\n",
      "fc8                    type DenseLayer           : output_shape=(None, 1000)\n",
      "prob                   type NonlinearityLayer    : output_shape=(None, 1000)\n"
     ]
    }
   ],
   "source": [
    "for name, layer in vgg16.network.items():\n",
    "    print('{: <22} type {: <21}: output_shape={}'.format(name, type(layer).__name__, layer.output_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The network builder function returns the last layer of the pre-trained model, nothing more\n",
    "def build_network(input_vars):\n",
    "    return vgg16.final_layer\n",
    "\n",
    "# Build the image classifier for the given model builder\n",
    "print('Building network')\n",
    "# We can't use the `simple_classifier` function, as we have to supply the input variables, so use\n",
    "# the `classifier` function. Also, tell the `classifier` function that the model includes\n",
    "# the softmax non-linearity in the final layer, so that it does not add a second one\n",
    "clf = basic_dnn.classifier(None, build_network, includes_softmax=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the classifier to predict the class of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the image for use with VGG-16; this will scale and crop to 224x224,\n",
    "# flip RGB to BGR channel order, subtract the mean value, etc...\n",
    "raw_img, img_for_vgg = vgg16.prepare_image(img)\n",
    "\n",
    "# Predict probabilities for the image\n",
    "img_pred_prob = clf.predict([img_for_vgg])[0]\n",
    "\n",
    "# Print the predicted probability shape\n",
    "print(img_pred_prob.shape)\n",
    "\n",
    "# Find the predicted class and display it\n",
    "pred_cls = np.argmax(img_pred_prob, axis=1)\n",
    "print('Predicted class index {} with probability {:.2%}, named \"{}\"'.format(\n",
    "    pred_cls[0], img_pred_prob[0, pred_cls[0]], vgg16.class_names[pred_cls[0]]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
